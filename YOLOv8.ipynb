{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krupaltisgaonkar/pytorch-yolo/blob/main/YOLOv8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5iOQzj5C6C_"
      },
      "source": [
        "# **YOLOv8 Training**\n",
        "**Author:** Krupal Tisgaonkar\n",
        "\n",
        "**Last updated:** January 18, 2025\n",
        "\n",
        "---\n",
        "\n",
        "This notebook helps you:\n",
        "1. Upload or import a dataset from Google Drive.\n",
        "2. Resize images and labels for YOLO format\n",
        "3. Train a YOLOv8 model using the processed dataset.\n",
        "4. Save and download the trained model.\n",
        "5. You will be able to deploy on a local machine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm1ykK1XC6DC"
      },
      "source": [
        "## **Step 1: Setup Environment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TmfQ4ajgC6DC",
        "outputId": "7448deab-3655-4bc9-c1ff-7c32233c85df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.63-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.63-py3-none-any.whl (910 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m910.2/910.2 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.63 ultralytics-thop-2.0.14\n",
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install ultralytics\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create necessary directories\n",
        "os.makedirs(\"dataset\", exist_ok=True)\n",
        "os.makedirs(\"processed_dataset\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hgR7xPiC6DE"
      },
      "source": [
        "## **Step 2: Upload or Import Dataset**\n",
        "\n",
        "1. Upload a zipped dataset manually.\n",
        "2. Provide the path to a zipped dataset stored in Google Drive.\n",
        "\n",
        "Structure your dataset as follows:\n",
        "\n",
        "```\n",
        "dataset/\n",
        "├── images/\n",
        "│   ├── train/\n",
        "│   ├── val/\n",
        "├── labels/\n",
        "│   ├── train/\n",
        "│   ├── val/\n",
        "```\n",
        "\n",
        "If your dataset isn't set like that, after this step, do Step A, otherwise don't do that step\n",
        "\n",
        "> **NOTE**: Make sure to name your dataset dataset.zip\n",
        "\n",
        "**Option 1: Upload zipped dataset manually**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ODrnHmzC6DF"
      },
      "outputs": [],
      "source": [
        "print(\"Upload your zipped dataset...\")\n",
        "uploaded = files.upload()\n",
        "# Extract the uploaded dataset\n",
        "if uploaded:\n",
        "    for filename in uploaded.keys():\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall(\"custom_data\")\n",
        "        print(f\"Dataset extracted to: custom_data/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkNW-PgeC6DF"
      },
      "source": [
        "**Option 2: Import from Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "O4rZf7ZsC6DF",
        "outputId": "46d71029-e986-4bee-d08b-8705b2eb08ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset extracted from Google Drive to: custom_data/\n"
          ]
        }
      ],
      "source": [
        "drive_dataset_path = \"/content/drive/MyDrive/dataset/YOLO/dataset.zip\"  # Replace with your Google Drive dataset path\n",
        "if os.path.exists(drive_dataset_path):\n",
        "    with zipfile.ZipFile(drive_dataset_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"custom_data\")\n",
        "    print(f\"Dataset extracted from Google Drive to: custom_data/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qORtkMttC6DG"
      },
      "source": [
        "### Step A: Make Dataset Compatible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6G7SFsIbC6DG",
        "outputId": "e997f5d0-f3d6-4b59-c51c-4f71649e42b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-18 18:56:19--  https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/utils/train_val_split.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3203 (3.1K) [text/plain]\n",
            "Saving to: ‘/content/train_val_split.py’\n",
            "\n",
            "/content/train_val_ 100%[===================>]   3.13K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-01-18 18:56:19 (53.4 MB/s) - ‘/content/train_val_split.py’ saved [3203/3203]\n",
            "\n",
            "Created folder at /content/data/train/images.\n",
            "Created folder at /content/data/train/labels.\n",
            "Created folder at /content/data/validation/images.\n",
            "Created folder at /content/data/validation/labels.\n",
            "Number of image files: 131\n",
            "Number of annotation files: 120\n",
            "Images moving to train: 117\n",
            "Images moving to validation: 14\n"
          ]
        }
      ],
      "source": [
        "!wget -O /content/train_val_split.py https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/utils/train_val_split.py\n",
        "\n",
        "# TO DO: Improve robustness of train_val_split.py script so it can handle nested data folders, etc\n",
        "!python train_val_split.py --datapath=\"/content/custom_data\" --train_pct=0.9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-1Um30bC6DH"
      },
      "source": [
        "## **Step 3: Resize Images to 640x640**\n",
        "\n",
        "Resize all images in the `train` and `val` directories to `640x640`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uaNLje9mC6DH",
        "outputId": "1586be7d-b528-4e89-ec5f-77261aa004d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images resized and saved to processed_dataset/train/images.\n",
            "Images resized and saved to processed_dataset/val/images.\n"
          ]
        }
      ],
      "source": [
        "# Function to resize images\n",
        "def resize_images(input_dir, output_dir, new_size=(640, 640)):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "            img_path = os.path.join(input_dir, filename)\n",
        "            img = Image.open(img_path)\n",
        "            img_resized = img.resize(new_size)\n",
        "            img_resized.save(os.path.join(output_dir, filename))\n",
        "    print(f\"Images resized and saved to {output_dir}.\")\n",
        "\n",
        "# Resize train and val images\n",
        "resize_images(\"data/train/images\", \"processed_dataset/train/images\")\n",
        "resize_images(\"data/validation/images\", \"processed_dataset/val/images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twbDpuyWC6DH"
      },
      "source": [
        "## **Step 4: Resize Labels**\n",
        "\n",
        "Adjust YOLO-format labels to align with the new image size. For the"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ocPbbfL6C6DI",
        "outputId": "66133826-59a7-46a6-ae78-7b46eff6448d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-18 18:58:27--  https://raw.githubusercontent.com/krupaltisgaonkar/pytorch/refs/heads/main/scripts/resize_labels.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4420 (4.3K) [text/plain]\n",
            "Saving to: ‘/content/resize_labels.py’\n",
            "\n",
            "/content/resize_lab 100%[===================>]   4.32K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-01-18 18:58:27 (44.2 MB/s) - ‘/content/resize_labels.py’ saved [4420/4420]\n",
            "\n",
            "Resized labels saved to processed_dataset/train/labels/image27.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image118.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image104.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image35.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image86.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image66.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image5.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image133.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image144.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image95.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image73.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image99.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image57.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image67.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image130.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image132.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image40.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image141.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image75.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image102.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image16.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image110.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image70.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image139.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image127.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image20.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image146.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image106.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image138.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image28.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image11.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image29.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image122.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image3.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image88.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image97.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image136.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image129.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image96.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image55.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image4.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image36.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image8.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image63.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image117.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image105.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image69.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image94.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image147.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image101.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image124.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image115.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image76.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image43.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image82.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image74.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image46.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image112.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image113.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image91.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image41.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image42.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image13.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image9.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image32.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image80.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image53.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image24.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image48.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image10.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image145.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image84.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image25.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image39.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image50.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image125.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image78.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image77.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image52.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image45.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image143.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image92.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image85.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image12.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image123.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image18.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image47.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image22.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image19.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image98.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image71.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image56.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image126.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image31.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image51.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image142.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image83.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image60.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image120.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image109.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image134.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image23.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image62.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image100.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image59.txt.\n",
            "Resized labels saved to processed_dataset/train/labels/image93.txt.\n",
            "Resized labels saved to processed_dataset/val/labels/image64.txt.\n",
            "Resized labels saved to processed_dataset/val/labels/image137.txt.\n",
            "Resized labels saved to processed_dataset/val/labels/image37.txt.\n",
            "Resized labels saved to processed_dataset/val/labels/image33.txt.\n",
            "Resized labels saved to processed_dataset/val/labels/image121.txt.\n",
            "Resized labels saved to processed_dataset/val/labels/image131.txt.\n",
            "Resized labels saved to processed_dataset/val/labels/image81.txt.\n",
            "Resized labels saved to processed_dataset/val/labels/image128.txt.\n",
            "Resized labels saved to processed_dataset/val/labels/image7.txt.\n",
            "Resized labels saved to processed_dataset/val/labels/image58.txt.\n",
            "Resized labels saved to processed_dataset/val/labels/image119.txt.\n",
            "Resized labels saved to processed_dataset/val/labels/image1.txt.\n",
            "Resized labels saved to processed_dataset/val/labels/image6.txt.\n",
            "Resized labels saved to processed_dataset/val/labels/image21.txt.\n"
          ]
        }
      ],
      "source": [
        "!wget -O /content/resize_labels.py https://raw.githubusercontent.com/krupaltisgaonkar/pytorch/refs/heads/main/scripts/resize_labels.py\n",
        "\n",
        "!python resize_labels.py --input_label_dir data/train/labels \\\n",
        "                 --input_image_dir data/train/images \\\n",
        "                 --output_label_dir processed_dataset/train/labels \\\n",
        "                 --new_size 640\n",
        "!python resize_labels.py --input_label_dir data/validation/labels \\\n",
        "                 --input_image_dir data/validation/images \\\n",
        "                 --output_label_dir processed_dataset/val/labels/ \\\n",
        "                 --new_size 640"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3ZTQkMbC6DI"
      },
      "source": [
        "## **Step 5: Train YOLOv8**\n",
        "\n",
        "Use the resized dataset to train a YOLOv8 model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!mkdir datasets\n",
        "!cp -r /content/processed_dataset /content/datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S1wJ6LBIE3k",
        "outputId": "a0087ab6-c055-4d2e-be51-33078333c62c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a data.yaml file for YOLO"
      ],
      "metadata": {
        "id": "P98jMqmdHg_J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xPp_RnhiC6DI",
        "outputId": "d274f762-2e62-4724-9dba-6f9103c4bf34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created config file at /content/data.yaml\n",
            "\n",
            "File contents:\n",
            "\n",
            "path: /content/processed_dataset\n",
            "train: train/images\n",
            "val: val/images\n",
            "nc: 1\n",
            "names:\n",
            "- fish\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "import os\n",
        "\n",
        "def create_data_yaml(path_to_classes_txt, path_to_data_yaml):\n",
        "\n",
        "  # Read class.txt to get class names\n",
        "  if not os.path.exists(path_to_classes_txt):\n",
        "    print(f'classes.txt file not found! Please create a classes.txt labelmap and move it to {path_to_classes_txt}')\n",
        "    return\n",
        "  with open(path_to_classes_txt, 'r') as f:\n",
        "    classes = []\n",
        "    for line in f.readlines():\n",
        "      if len(line.strip()) == 0: continue\n",
        "      classes.append(line.strip())\n",
        "  number_of_classes = len(classes)\n",
        "\n",
        "  # Create data dictionary\n",
        "  data = {\n",
        "      'path': '/content/processed_dataset',\n",
        "      'train': 'train/images',\n",
        "      'val': 'val/images',\n",
        "      'nc': number_of_classes,\n",
        "      'names': classes\n",
        "  }\n",
        "\n",
        "  # Write data to YAML file\n",
        "  with open(path_to_data_yaml, 'w') as f:\n",
        "    yaml.dump(data, f, sort_keys=False)\n",
        "  print(f'Created config file at {path_to_data_yaml}')\n",
        "\n",
        "  return\n",
        "\n",
        "# Define path to classes.txt and run function\n",
        "path_to_classes_txt = '/content/data/classes.txt'\n",
        "path_to_data_yaml = '/content/data.yaml'\n",
        "\n",
        "create_data_yaml(\"custom_data/classes.txt\", \"/content/data.yaml\")\n",
        "\n",
        "print('\\nFile contents:\\n')\n",
        "!cat /content/data.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start Training!\n",
        "\n",
        "\n",
        "\n",
        "> **NOTE:** Your model might need more epochs if it has less images\n",
        "\n",
        "After training this will already download the model.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GNuPg9YtHoXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo detect train data=/content/data.yaml model=yolo11s.pt epochs=2500 imgsz=640 patience=2501\n",
        "\n",
        "# Create \"my_model\" folder to store model weights and train results\n",
        "!mkdir /content/fish_detect\n",
        "!cp /content/runs/detect/train/weights/best.pt /content/fish_detect/my_model.pt\n",
        "!cp -r /content/runs/detect/train /content/fish_detect\n",
        "\n",
        "# Zip into \"my_model.zip\"\n",
        "%cd fish_detect\n",
        "!zip /content/fish_detect.zip model.pt\n",
        "!zip -r /content/fish_detect.zip train\n",
        "%cd /content\n",
        "files.download('/content/fish_detect.zip')"
      ],
      "metadata": {
        "id": "uMvPjgD0Hp_c",
        "outputId": "3ffb7914-3675-422f-befd-6af8820ba11e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s.pt to 'yolo11s.pt'...\n",
            "100% 18.4M/18.4M [00:00<00:00, 256MB/s]\n",
            "Ultralytics 8.3.63 🚀 Python-3.11.11 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11s.pt, data=/content/data.yaml, epochs=2500, time=None, patience=2501, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 20.5MB/s]\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
            " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
            " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
            " 23        [16, 19, 22]  1    819795  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
            "YOLO11s summary: 319 layers, 9,428,179 parameters, 9,428,163 gradients, 21.5 GFLOPs\n",
            "\n",
            "Transferred 493/499 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
            "100% 5.35M/5.35M [00:00<00:00, 117MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/processed_dataset/train/labels... 106 images, 11 backgrounds, 0 corrupt: 100% 117/117 [00:00<00:00, 839.03it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/processed_dataset/train/labels.cache\n",
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.0 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/processed_dataset/val/labels... 14 images, 0 backgrounds, 0 corrupt: 100% 14/14 [00:00<00:00, 359.43it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/processed_dataset/val/labels.cache\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 2500 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     1/2500      5.62G       2.79      3.632       2.03        132        640: 100% 8/8 [00:08<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.81s/it]\n",
            "                   all         14        524      0.217      0.248      0.125     0.0314\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     2/2500       5.2G      2.568      2.636      1.887        120        640: 100% 8/8 [00:02<00:00,  3.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.81it/s]\n",
            "                   all         14        524      0.336      0.307      0.208     0.0606\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     3/2500      5.32G      2.438       2.06      1.669        369        640:  38% 3/8 [00:01<00:01,  2.81it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
            "     3/2500      6.21G      2.407      2.086      1.655        262        640: 100% 8/8 [00:02<00:00,  2.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.83it/s]\n",
            "                   all         14        524      0.266      0.279      0.156      0.046\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     4/2500      5.83G      2.376      2.014       1.57        113        640: 100% 8/8 [00:03<00:00,  2.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.67it/s]\n",
            "                   all         14        524      0.199      0.267      0.108      0.032\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     5/2500      5.57G      2.355       1.96      1.614         43        640: 100% 8/8 [00:02<00:00,  3.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.68it/s]\n",
            "                   all         14        524      0.296      0.334      0.173      0.051\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     6/2500      5.67G      2.434      1.916      1.636        489        640:  62% 5/8 [00:01<00:00,  3.11it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: **Deploy on Local Machine**"
      ],
      "metadata": {
        "id": "rL2Jnw5SyWyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Anaconda Prompt, or you can just create a virtual environment by yourself.\n",
        "\n",
        "Name it whatever you want I named mine `yolo-env1`. Also ensure it is python 3.12.\n",
        "\n",
        "For Anaconda, I used this command:\n",
        "\n",
        "```\n",
        "conda create --name yolo-env1 python=3.12 -y\n",
        "conda activate yolo-env1\n",
        "```\n",
        "Now install Ultralytics by using\n",
        "\n",
        "```\n",
        "pip install ultralytics\n",
        "```\n",
        "\n",
        "If you have a NVIDIA GPU, CUDA enabled on your local computer, use this command to install the packages\n",
        "\n",
        "```\n",
        "pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
        "```\n",
        "\n",
        "If you **DO NOT** have a GPU, or the proper GPU, use this command to download the CPU version:\n",
        "\n",
        "```\n",
        "pip install torch torchvision torchaudio\n",
        "```\n",
        "\n",
        "Now to run this model, you will have to download the code from my github page.\n",
        "\n",
        "You can use either:\n",
        "\n",
        "```\n",
        "curl -o model_main.py https://raw.githubusercontent.com/krupaltisgaonkar/pytorch/refs/heads/main/scripts/model_main.py\n",
        "```\n",
        "\n",
        "or\n",
        "\n",
        "```\n",
        "wget -O model_main.py https://raw.githubusercontent.com/krupaltisgaonkar/pytorch/refs/heads/main/scripts/model_main.py\n",
        "```\n",
        "\n",
        "**REMEMBER TO CHANGE YOUR CUSTOM MODELS VARIABLE'S PATHS TO THE PATHS OF YOUR MODELS!!! IN THE CODE**\n",
        "\n",
        "\n",
        "Run the command:\n",
        "\n",
        "Use a YOLO Predefined Model (v5, v8, v11) with Webcam\n",
        "\n",
        "```\n",
        "python model_main.py --model v8 --webcam 0\n",
        "```\n",
        "\n",
        "Use a YOLO Predefined Model with an Image or Video or Directory\n",
        "\n",
        "```bash\n",
        "python model_main.py --model v5 --input ./data/image.jpg\n",
        "python model_main.py --model v11 --input ./data/video.mp4\n",
        "python model_main.py --model v11 --input ./data/\n",
        "```\n",
        "Use your custom model\n",
        "```\n",
        "python model_main.py --model custom1 --input ./data/image.jpg\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "N5LuelDdycqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Errors**\n",
        "\n",
        "If you have question, go to the github repository, and under issues, put an issue."
      ],
      "metadata": {
        "id": "KYtXhnxkUVLk"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}